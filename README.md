1. Need to start ollama in local
2. run this LLM in local
https://ollama.com/library/deepseek-r1:1.5b
ollama run deepseek-r1:1.5b
3. Ollama chat reference link:
https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html
4. start Spring Boot app

End Points to test:
http://localhost:8080

